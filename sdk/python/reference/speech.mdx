---
title: 'Speech'
description: 'Reference for the Speech class in the Python SDK'
---

<Note>
Make sure that you have installed the SDK properly. [Installation](/sdk/python/introduction#getting-started)
</Note>

The `Speech` class is your primary touch-point with the LMNT API.

Instantiate a `Speech` object with your <Tooltip tip='Create an API key by visiting your account page in our speech playground and signing up for a (free) plan.'>[LMNT API key](/api-reference/authentication):</Tooltip>

```python
from lmnt.api import Speech

speech = Speech('LMNT_API_KEY')
```

When you're done with the `Speech` instance, make sure to clean up by calling its `close()` method. 

```python
await speech.close()
```

Alternatively, you can use this class as an async context manager, which will call `close()` for you:

```python
async with Speech('LMNT_API_KEY') as speech:
  pass
```
-----------

## list_voices

> `async list_voices(**kwargs)`

Returns the voices available for use in speech synthesis calls.

```python
voices = await speech.list_voices()
```

### Parameters
- `starred` bool (optional): if `true`, only return starred voices; Defaults to `false`
- `owner` str (optional): Specify which voices to return. Choose from `system`, `me`, or `all`. Defaults to `all`.

### Return value
A list of voice metadata objects. Here's a sample object:

```javascript
[
  {
    "name": "Curtis",
    "id": "curtis",
    "state": "ready",
    "owner": "system",
    "starred": false,
    "gender": "male",
    "description": "Curtis' voice carries the seasoned timbre of middle age, filled with warmth, curiosity, and a hint of wisdom gained over the years."
  }
]
```

-----------

## voice_info

> `async voice_info(voice_id)`

Returns details of a specific voice.

```python
voice = await speech.voice_info('voice_id')
```

### Parameters
- `voice_id` str: The id of the voice to update. If you don't know the id, you can get it from `list_voices()`.

### Return value
The voice metadata object (A dictionary containing details of the voice). Here's a sample object:

```javascript
  {
    "name": "Curtis",
    "id": "curtis",
    "state": "ready",
    "owner": "system",
    "starred": false,
    "gender": "male",
    "description": "Curtis' voice carries the seasoned timbre of middle age, filled with warmth, curiosity, and a hint of wisdom gained over the years."
  }
```

-----------

## create_voice
> `async create_voice(name, enhance, filenames, **kwargs)`

Creates a new voice from a set of audio files. Returns the voice metadata object.

```python
voice = await speech.create_voice('new-voice', True, ['file1.mp3', 'file2.mp3'])
```

### Parameters
- `name` str: the name of the voice
- `enhance` bool: For unclean audio with background noise, applies processing to attempt to improve quality. Not on by default as it can also degrade quality in some circumstances.
- `filenames` [str]: A list of filenames to use for the voice.
- Optional Parameters
    - `type` str: The type of voice to create. Must be one of `instant` or `professional`. Defaults to `instant`.
    - `gender` str: The gender of the voice, e.g. `male`, `female`, `nonbinary`. For categorization purposes. Defaults to `None`.
    - `description` str: A description of the voice. Defaults to `None`.

### Return value
The voice metadata object. Here's a sample object:

```javascript
{
    "id": "123444566422",
    "name": "new-voice",
    "owner": "me",
    "state": "ready",
    "starred": false,
    "description": "Totam necessitatibus saepe repudiandae perferendis. Tempora iure provident. Consequatur debitis assumenda. Earum debitis cum.",
    "type": "instant",
    "gender": "male"
}
```

-----------

## update_voice
> `async update_voice(voice_id, **kwargs)`

Updates metadata for a specific voice. A voice that is not owned by you can only have its `starred` field updated. 
Only provided fields will be changed.

```python
updated_voice = await speech.update_voice('voice_id', name='new-voice', starred=True)
```

### Parameters
- `voice_id` str: The id of the voice to update. If you don't know the id, you can get it from `list_voices()`.
- Optional Parameters:
    - `name` str: The name of the voice
    - `starred` bool: Whether the voice is starred by you
    - `gender` str: The gender of the voice, e.g. `male`, `female`, `nonbinary`. For categorization purposes.
    - `description` str: A description of the voice.

### Return value
The updated voice metadata object.

-----------

## delete_voice
> `async delete_voice(voice_id)`

Deletes a voice and cancels any pending operations on it. The voice must be owned by you. Cannot be undone.

```python
await speech.delete_voice('voice_id')
```

### Parameters
- `voice_id` str: The id of the voice to delete. If you don't know the id, you can get it from `list_voices()`.

### Return value
A success or error message. Here's a sample object:

```javascript
{
    "success": "true"
}
```

-----------

## close

> `async close()`

Releases resources associated with this instance.

```python
await speech.close()
```

-----------

## synthesize

> `async synthesize(text, voice, **kwargs)`

Synthesizes speech for a supplied text string.

### Parameters
- `text` str: The text to synthesize
- `voice` str: Which voice to render; id is found using the `list_voices` call
- `**kwargs`
    - `format` str: `aac`, `mp3`, `wav`; Defaults to `mp3` (24kHz 16-bit mono)
    - `length` float: Produce speech of this length in seconds; maximum 300.0 (5 minutes).
    - `return_durations` bool: Whether to include word durations detail in the response; Defaults to false
    - `return_seed` bool: Whether to include the seed used for synthesis in the response; Defaults to false
    - `speed` float: Floating point value between 0.25 (slow) and 2.0 (fast); Defaults to 1.0
    - `seed` int: The seed used to specify a different take; Defaults to a random value.

### Return value
An object with the following keys:
- `audio`: The binary audio file.
- `durations`: The word durations detail. Only returned if `return_durations` is `True`.
- `seed`: The seed used for synthesis. Only returned if `return_seed` is `True`.

Each `durations` entry is a dictionary describing the duration of each 'word' with the following keys:
- `text`: The 'word' itself
- `start`: The time at which the 'word' starts, in seconds
- `duration`: The overall duration of the 'word', in seconds

Here is the schema for the return value:

```javascript
{
  "audio": binary-audio-file,
  "durations": [
    {
      "text": "string",
      "start": 0,
      "duration": 0
    }
  ],
  "seed": "string"
}
```

### Notes
- The `mp3` bitrate is 96kbps.
- The `length` parameter specifies how long you want the output speech to be. We will automatically speed up / slow down the speech as needed to fit this length.

-----------

## synthesize_streaming
> `async synthesize_streaming(voice, **kwargs)`

Creates a new, full-duplex streaming session. You can use the returned session object to concurrently stream text content to the server
and receive speech data from the server.

### Parameters
- `voice` string: which voice to render; id is found using the `list_voices` call
- Optional Parameters
    - `speed` float: Floating point value between 0.25 (slow) and 2.0 (fast); Defaults to 1.0.
    - `return_extras` bool: Whether to return extra data (durations data and warnings) with each audio chunk.

### Return value
A `StreamingSynthesisConnection` instance, which you can use to stream data.
